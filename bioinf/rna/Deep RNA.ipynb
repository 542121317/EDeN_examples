{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "configure_logging(logger,verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "def save_data(data, fname='data.dat'):\n",
    "    with open(fname, 'wb') as outfile:\n",
    "        pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    if len(data.shape)==1:\n",
    "        print 'Saved %s (%d)' % (fname, data.shape[0])\n",
    "    else:\n",
    "        print 'Saved %s (%d,%d)' % (fname, data.shape[0], data.shape[1])\n",
    "\n",
    "def load_data(fname='data.dat'):\n",
    "    with open(fname, 'rb') as infile:\n",
    "        data = pickle.load(infile)\n",
    "    if len(data.shape)==1:\n",
    "        print 'Loaded %s (%d)' % (fname, data.shape[0])\n",
    "    else:\n",
    "        print 'Loaded %s (%d,%d)' % (fname, data.shape[0], data.shape[1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Predicitve model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_perform(X_train, y_train, X_test,y_test):\n",
    "    # Induce a predictive model\n",
    "    print 'Training on data matrix [%d x %d]' %(X_train.shape)\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
    "    estimator.fit(X_train,y_train)\n",
    "\n",
    "    # Print predictive performance\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print 'Confusion matrix:'\n",
    "    print(confusion_matrix(y_test, estimator.predict(X_test)))\n",
    "    print\n",
    "    from sklearn.metrics import classification_report\n",
    "    print 'Classification Report:'\n",
    "    print classification_report(y_test, estimator.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train/test according to binary clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_ids_split(X, confidence_threshold=1):\n",
    "    from sklearn.cluster import MiniBatchKMeans\n",
    "    kmeans = MiniBatchKMeans(n_clusters=2)\n",
    "    classes = kmeans.fit_predict(X)\n",
    "    \n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
    "    estimator.fit(X,classes)\n",
    "    conf = estimator.decision_function(X)\n",
    "    \n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    for i,(class_info, conf_info) in enumerate(zip(classes, conf)):\n",
    "        if abs(conf_info) > confidence_threshold:\n",
    "            if class_info == 0:\n",
    "                train_ids.append(i)\n",
    "            else:\n",
    "                test_ids.append(i)\n",
    "    return train_ids, test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve seed sequences from RFam families.\n",
    "\n",
    "Use EDeN to transform sequences to vectors. Use RNAfold to create structures and EDeN to convert those to vectors.\n",
    "\n",
    "Use the sequence vectors to guide the train/test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num families: 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection\n",
    "import time\n",
    "\n",
    "def rfam_uri(family_id):\n",
    "        return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "\n",
    "#RNAfold\n",
    "def pre_processor(seqs):\n",
    "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
    "    graphs = rnafold_to_eden(seqs)\n",
    "    from eden.modifier.graph import structure \n",
    "    graphs = structure.basepair_to_nesting(graphs)\n",
    "    return graphs\n",
    "\n",
    "    \n",
    "#RNAVectorizer\n",
    "def pre_processor(seqs):\n",
    "    n_neighbors = min(len(seqs),30)\n",
    "    rs = int(time.time())\n",
    "    from eden.RNA import Vectorizer as RNAVectorizer\n",
    "    rnavec=RNAVectorizer(n_neighbors=n_neighbors,\n",
    "                         sampling_prob=.15,\n",
    "                         n_iter=5,\n",
    "                         min_energy=-5,\n",
    "                         random_state=rs)\n",
    "    rnavec.fit(seqs)\n",
    "    graphs = rnavec.graphs(seqs)\n",
    "    from eden.modifier.graph import structure \n",
    "    graphs = structure.basepair_to_nesting(graphs)\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def rfam_to_matrix(rfam_id, use_structure=True, n_max=50, complexity=2, nbits=10):\n",
    "    from eden.converter.fasta import fasta_to_sequence\n",
    "    seqs = fasta_to_sequence(rfam_uri(rfam_id))\n",
    "    from itertools import islice\n",
    "    seqs = islice(seqs,n_max)\n",
    "    seqs = list(seqs)\n",
    "    if use_structure:\n",
    "        graphs = pre_processor(seqs)\n",
    "        from eden.graph import Vectorizer as GraphVectorizer\n",
    "        vectorizer = GraphVectorizer(r=3,d=0,\n",
    "                                     normalization=False,\n",
    "                                     inner_normalization=False,\n",
    "                                     nbits=nbits)\n",
    "        X = vectorizer.transform(graphs)\n",
    "    else:\n",
    "        from eden.path import Vectorizer as SeqVectorizer\n",
    "        vectorizer = SeqVectorizer(r=3,d=20,\n",
    "                                   normalization=False,\n",
    "                                   inner_normalization=False,\n",
    "                                   nbits=nbits)\n",
    "        X = vectorizer.transform(seqs)\n",
    "    return X\n",
    "\n",
    "def rfam_data(rfam_ids, n_max=300, complexity=3, nbits=13):\n",
    "    import numpy as np\n",
    "    from scipy.sparse import vstack\n",
    "    seq_train_list = []\n",
    "    seq_test_list = []\n",
    "    struct_train_list = []\n",
    "    struct_test_list = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for i,rfam_id in enumerate(rfam_ids):\n",
    "        # seq case\n",
    "        seq_X=rfam_to_matrix(rfam_id, use_structure=False, n_max=n_max, complexity=complexity, nbits=nbits)\n",
    "        train_ids, test_ids = train_test_ids_split(seq_X)\n",
    "        seq_X_train = seq_X[train_ids]\n",
    "        seq_X_test = seq_X[test_ids]\n",
    "        seq_train_list.append(seq_X_train)\n",
    "        seq_test_list.append(seq_X_test)\n",
    "        y_train += [i] * seq_X_train.shape[0]\n",
    "        y_test += [i] * seq_X_test.shape[0]\n",
    "        \n",
    "        # struct case\n",
    "        struct_X=rfam_to_matrix(rfam_id, use_structure=True, n_max=n_max, complexity=complexity, nbits=nbits)\n",
    "        #NOTE: use the same split given by the sequence similarity\n",
    "        struct_X_train = struct_X[train_ids]\n",
    "        struct_X_test = struct_X[test_ids]\n",
    "        struct_train_list.append(struct_X_train)\n",
    "        struct_test_list.append(struct_X_test)\n",
    "    seq_X_train = vstack(seq_train_list, format=\"csr\")\n",
    "    seq_X_test = vstack(seq_test_list, format=\"csr\")\n",
    "    struct_X_train = vstack(struct_train_list, format=\"csr\")\n",
    "    struct_X_test = vstack(struct_test_list, format=\"csr\")\n",
    "    target_train = np.array(y_train)\n",
    "    target_test = np.array(y_test)\n",
    "    \n",
    "    return seq_X_train,\\\n",
    "        seq_X_test,\\\n",
    "        struct_X_train,\\\n",
    "        struct_X_test,\\\n",
    "        target_train,\\\n",
    "        target_test\n",
    "\n",
    "rfam_ids=['RF00004','RF00005','RF00015','RF00020','RF00026','RF00169',\n",
    "          'RF00380','RF00386','RF01051','RF01055','RF01234','RF01699',\n",
    "          'RF01701','RF01705','RF01731','RF01734','RF01745','RF01750',\n",
    "          'RF01942','RF01998','RF02005','RF02012','RF02034']\n",
    "\n",
    "print 'num families:', len(rfam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment using 5 families\n"
     ]
    }
   ],
   "source": [
    "data_ids=rfam_ids[0:5]\n",
    "print 'Experiment using %d families' % len(data_ids)\n",
    "prefix='f3_c4nb12_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 40.1 s, total: 2min 24s\n",
      "Wall time: 7min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq_X_train,\\\n",
    "seq_X_test,\\\n",
    "struct_X_train,\\\n",
    "struct_X_test,\\\n",
    "y_train,\\\n",
    "y_test = rfam_data(data_ids, n_max=300, complexity=4, nbits=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved f3_c4nb12_seq_X_train.dat (575,4097)\n",
      "Saved f3_c4nb12_seq_X_test.dat (471,4097)\n",
      "Saved f3_c4nb12_struct_X_train.dat (575,4097)\n",
      "Saved f3_c4nb12_struct_X_test.dat (471,4097)\n",
      "Saved f3_c4nb12_y_train.dat (575)\n",
      "Saved f3_c4nb12_y_test.dat (471)\n",
      "CPU times: user 14.4 ms, sys: 76.3 ms, total: 90.8 ms\n",
      "Wall time: 568 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_data(seq_X_train, fname=prefix+'seq_X_train.dat')\n",
    "save_data(seq_X_test, fname=prefix+'seq_X_test.dat')\n",
    "save_data(struct_X_train, fname=prefix+'struct_X_train.dat')\n",
    "save_data(struct_X_test, fname=prefix+'struct_X_test.dat')\n",
    "save_data(y_train, fname=prefix+'y_train.dat')\n",
    "save_data(y_test, fname=prefix+'y_test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded f3_c4nb12_seq_X_train.dat (575,4097)\n",
      "Loaded f3_c4nb12_seq_X_test.dat (471,4097)\n",
      "Loaded f3_c4nb12_struct_X_train.dat (575,4097)\n",
      "Loaded f3_c4nb12_struct_X_test.dat (471,4097)\n",
      "Loaded f3_c4nb12_y_train.dat (575)\n",
      "Loaded f3_c4nb12_y_test.dat (471)\n",
      "CPU times: user 15 ms, sys: 38.5 ms, total: 53.5 ms\n",
      "Wall time: 52.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq_X_train=load_data(fname=prefix+'seq_X_train.dat')\n",
    "seq_X_test=load_data(fname=prefix+'seq_X_test.dat')\n",
    "struct_X_train=load_data(fname=prefix+'struct_X_train.dat')\n",
    "struct_X_test=load_data(fname=prefix+'struct_X_test.dat')\n",
    "y_train=load_data(fname=prefix+'y_train.dat')\n",
    "y_test=load_data(fname=prefix+'y_test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 µs, sys: 5.15 ms, total: 5.2 ms\n",
      "Wall time: 5.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sparse to dense arrays\n",
    "Xseq_train = seq_X_train\n",
    "Xseq_test = seq_X_test\n",
    "X_train = struct_X_train\n",
    "X_test = struct_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.7 ms, sys: 20.7 ms, total: 55.5 ms\n",
      "Wall time: 54.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sparse to dense arrays\n",
    "Xseq_train = seq_X_train.toarray()\n",
    "Xseq_test = seq_X_test.toarray()\n",
    "X_train = struct_X_train.toarray()\n",
    "X_test = struct_X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sequence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on data matrix [575 x 4097]\n",
      "Confusion matrix:\n",
      "[[ 43   6   3   2   0]\n",
      " [  0  32   1  13  18]\n",
      " [ 15  62  24   4   0]\n",
      " [  0  27   8  46   1]\n",
      " [  2  27   5   1 131]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.80      0.75        54\n",
      "          1       0.21      0.50      0.29        64\n",
      "          2       0.59      0.23      0.33       105\n",
      "          3       0.70      0.56      0.62        82\n",
      "          4       0.87      0.79      0.83       166\n",
      "\n",
      "avg / total       0.67      0.59      0.60       471\n",
      "\n",
      "CPU times: user 186 ms, sys: 6.57 ms, total: 192 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_perform(Xseq_train, y_train, Xseq_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Structure features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on data matrix [575 x 4097]\n",
      "Confusion matrix:\n",
      "[[ 54   0   0   0   0]\n",
      " [  7  23   6   4  24]\n",
      " [ 15  31  59   0   0]\n",
      " [ 10  22   3  46   1]\n",
      " [  4 102   3   1  56]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75        54\n",
      "          1       0.13      0.36      0.19        64\n",
      "          2       0.83      0.56      0.67       105\n",
      "          3       0.90      0.56      0.69        82\n",
      "          4       0.69      0.34      0.45       166\n",
      "\n",
      "avg / total       0.67      0.51      0.54       471\n",
      "\n",
      "CPU times: user 205 ms, sys: 4.76 ms, total: 210 ms\n",
      "Wall time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_perform(X_train, y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Learned map seq $\\mapsto$ structure features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons: #in [4097] -- #hidden [2048] -- #out [4097]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "seqs_scale = StandardScaler(with_mean=True)\n",
    "data_matrix_in = seqs_scale.fit_transform(Xseq_train)\n",
    "struct_scale = StandardScaler(with_mean=True)\n",
    "data_matrix_out = struct_scale.fit_transform(X_train)\n",
    "n_features_in = data_matrix_in.shape[1]\n",
    "n_features_out = data_matrix_out.shape[1]\n",
    "n_features_hidden = max(n_features_in, n_features_out) / 2\n",
    "print 'n_neurons: #in [%d] -- #hidden [%d] -- #out [%d]' % (n_features_in, n_features_hidden, n_features_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Regressor, Layer\n",
    "\n",
    "net = Regressor(layers=[\n",
    "        Layer(\"Rectifier\", units=n_features_hidden),\n",
    "        Layer(\"Rectifier\", units=n_features_hidden),\n",
    "        Layer(\"Rectifier\", units=n_features_hidden),\n",
    "        Layer(\"Linear\", units=n_features_out)],\n",
    "                learning_rate=0.0001,\n",
    "                n_iter=40,\n",
    "                batch_size=10,\n",
    "                regularize='L1',\n",
    "                valid_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 38s, sys: 1min 32s, total: 22min 10s\n",
      "Wall time: 10min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Regressor(batch_size=10, debug=False, dropout_rate=None, f_stable=0.001,\n",
       "     hidden0=<sknn.nn.Layer `Rectifier`: name=u'hidden0', units=2048>,\n",
       "     hidden1=<sknn.nn.Layer `Rectifier`: name=u'hidden1', units=2048>,\n",
       "     hidden2=<sknn.nn.Layer `Rectifier`: name=u'hidden2', units=2048>,\n",
       "     layers=[<sknn.nn.Layer `Rectifier`: name=u'hidden0', units=2048>, <sknn.nn.Layer `Rectifier`: name=u'hidden1', units=2048>, <sknn.nn.Layer `Rectifier`: name=u'hidden2', units=2048>, <sknn.nn.Layer `Linear`: name=u'output', units=4097>],\n",
       "     learning_momentum=0.9, learning_rate=0.0001, learning_rule=u'sgd',\n",
       "     loss_type=u'mse', mutator=None, n_iter=40, n_stable=50,\n",
       "     output=<sknn.nn.Layer `Linear`: name=u'output', units=4097>,\n",
       "     random_state=None, regularize='L1',\n",
       "     valid_set=(array([[ 0.     , -1.21392, ...,  0.62572,  0.43704],\n",
       "       [ 0.     ,  0.61331, ...,  0.62572, -1.23827],\n",
       "       ...,\n",
       "       [ 0.     ,  0.61331, ...,  0.62572,  0.43704],\n",
       "       [ 0.     ,  0.61331, ..., -1.34033,  2.11235]]), array([[ 0.     , -0.18782, ..., -0.16366,  0.     ],\n",
       "       [ 0.     , -0.18782, ..., -0.16366,  0.     ],\n",
       "       ...,\n",
       "       [ 0.     , -0.18782, ..., -0.16366,  0.     ],\n",
       "       [ 0.     , -0.18782, ..., -0.16366,  0.     ]])),\n",
       "     valid_size=0.1, verbose=None, weight_decay=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "net.fit(data_matrix_in, data_matrix_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.78 s, sys: 87.4 ms, total: 4.87 s\n",
      "Wall time: 804 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform seq features to struct features\n",
    "X_train_pred = net.predict(seqs_scale.transform(Xseq_train))\n",
    "X_test_pred = net.predict(seqs_scale.transform(Xseq_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on data matrix [575 x 4097]\n",
      "Confusion matrix:\n",
      "[[ 54   0   0   0   0]\n",
      " [  0  63   0   1   0]\n",
      " [ 46  11  36  11   1]\n",
      " [ 14  15   8  45   0]\n",
      " [  6 120  13  11  16]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      1.00      0.62        54\n",
      "          1       0.30      0.98      0.46        64\n",
      "          2       0.63      0.34      0.44       105\n",
      "          3       0.66      0.55      0.60        82\n",
      "          4       0.94      0.10      0.17       166\n",
      "\n",
      "avg / total       0.68      0.45      0.40       471\n",
      "\n",
      "CPU times: user 181 ms, sys: 8.63 ms, total: 189 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_perform(X_train_pred, y_train, X_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
