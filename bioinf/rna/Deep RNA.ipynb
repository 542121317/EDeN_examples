{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "configure_logging(logger,verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "def save_data(data, fname='data.dat'):\n",
    "    with open(fname, 'wb') as outfile:\n",
    "        pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "    if len(data.shape)==1:\n",
    "        print 'Saved %s (%d)' % (fname, data.shape[0])\n",
    "    else:\n",
    "        print 'Saved %s (%d,%d)' % (fname, data.shape[0], data.shape[1])\n",
    "\n",
    "def load_data(fname='data.dat'):\n",
    "    with open(fname, 'rb') as infile:\n",
    "        data = pickle.load(infile)\n",
    "    if len(data.shape)==1:\n",
    "        print 'Loaded %s (%d)' % (fname, data.shape[0])\n",
    "    else:\n",
    "        print 'Loaded %s (%d,%d)' % (fname, data.shape[0], data.shape[1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Predicitve model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_perform(X_train, y_train, X_test,y_test):\n",
    "    # Induce a predictive model\n",
    "    print 'Training on data matrix [%d x %d]' %(X_train.shape)\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, n_jobs=-1)\n",
    "    estimator.fit(X_train,y_train)\n",
    "\n",
    "    # Print predictive performance\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print 'Confusion matrix:'\n",
    "    print(confusion_matrix(y_test, estimator.predict(X_test)))\n",
    "    print\n",
    "    from sklearn.metrics import classification_report\n",
    "    print 'Classification Report:'\n",
    "    print classification_report(y_test, estimator.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train/test according to binary clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_ids_split(X, confidence_threshold=1):\n",
    "    from sklearn.cluster import MiniBatchKMeans\n",
    "    kmeans = MiniBatchKMeans(n_clusters=2)\n",
    "    classes = kmeans.fit_predict(X)\n",
    "    \n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(average=True, class_weight='balanced', shuffle=True, n_jobs=-1)\n",
    "    estimator.fit(X,classes)\n",
    "    conf = estimator.decision_function(X)\n",
    "    \n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    for i,(class_info, conf_info) in enumerate(zip(classes, conf)):\n",
    "        if abs(conf_info) > confidence_threshold:\n",
    "            if class_info == 0:\n",
    "                train_ids.append(i)\n",
    "            else:\n",
    "                test_ids.append(i)\n",
    "    return train_ids, test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve seed sequences from RFam families.\n",
    "\n",
    "Use EDeN to transform sequences to vectors. Use RNAfold to create structures and EDeN to convert those to vectors.\n",
    "\n",
    "Use the sequence vectors to guide the train/test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num families: 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection\n",
    "import time\n",
    "\n",
    "def rfam_uri(family_id):\n",
    "        return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "    \n",
    "#RNAVectorizer\n",
    "def pre_processor(seqs):\n",
    "    n_neighbors = min(len(seqs),30)\n",
    "    rs = int(time.time())\n",
    "    from eden.RNA import Vectorizer as RNAVectorizer\n",
    "    rnavec=RNAVectorizer(n_neighbors=n_neighbors,\n",
    "                         sampling_prob=.15,\n",
    "                         n_iter=5,\n",
    "                         min_energy=-5,\n",
    "                         random_state=rs)\n",
    "    rnavec.fit(seqs)\n",
    "    graphs = rnavec.graphs(seqs)\n",
    "    #from eden.modifier.graph import structure \n",
    "    #graphs = structure.basepair_to_nesting(graphs)\n",
    "    return graphs\n",
    "\n",
    "#RNAfold\n",
    "def pre_processor(seqs):\n",
    "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
    "    graphs = rnafold_to_eden(seqs)\n",
    "    #from eden.modifier.graph import structure \n",
    "    #graphs = structure.basepair_to_nesting(graphs)\n",
    "    return graphs\n",
    "\n",
    "#RNAplfold\n",
    "def pre_processor(seqs):\n",
    "    from eden.converter.rna.rnaplfold import rnaplfold_to_eden\n",
    "    graphs = rnaplfold_to_eden(seqs,\n",
    "                               window_size = 250,\n",
    "                               max_bp_span = 35,\n",
    "                               avg_bp_prob_cutoff = 0.01,\n",
    "                               max_num_edges = 10,\n",
    "                               no_lonely_bps=True,\n",
    "                               nesting=True)\n",
    "    return graphs\n",
    "    \n",
    "def rfam_to_matrix(rfam_id, use_structure=True, n_max=50, complexity=2, nbits=10):\n",
    "    from eden.converter.fasta import fasta_to_sequence\n",
    "    seqs = fasta_to_sequence(rfam_uri(rfam_id))\n",
    "    from itertools import islice\n",
    "    seqs = islice(seqs,n_max)\n",
    "    seqs = list(seqs)\n",
    "    if use_structure:\n",
    "        graphs = pre_processor(seqs)\n",
    "        from eden.graph import Vectorizer as GraphVectorizer\n",
    "        vectorizer = GraphVectorizer(complexity=complexity,nbits=nbits)\n",
    "        X = vectorizer.transform(graphs)\n",
    "    else:\n",
    "        from eden.path import Vectorizer as SeqVectorizer\n",
    "        vectorizer = SeqVectorizer(complexity=complexity,nbits=nbits)\n",
    "        X = vectorizer.transform(seqs)\n",
    "    return X\n",
    "\n",
    "def rfam_data(rfam_ids, n_max=300, complexity=3, nbits=13):\n",
    "    import numpy as np\n",
    "    from scipy.sparse import vstack\n",
    "    seq_train_list = []\n",
    "    seq_test_list = []\n",
    "    struct_train_list = []\n",
    "    struct_test_list = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for i,rfam_id in enumerate(rfam_ids):\n",
    "        # seq case\n",
    "        seq_X=rfam_to_matrix(rfam_id, use_structure=False, n_max=n_max, complexity=complexity, nbits=nbits)\n",
    "        train_ids, test_ids = train_test_ids_split(seq_X)\n",
    "        seq_X_train = seq_X[train_ids]\n",
    "        seq_X_test = seq_X[test_ids]\n",
    "        seq_train_list.append(seq_X_train)\n",
    "        seq_test_list.append(seq_X_test)\n",
    "        y_train += [i] * seq_X_train.shape[0]\n",
    "        y_test += [i] * seq_X_test.shape[0]\n",
    "        \n",
    "        # struct case\n",
    "        struct_X=rfam_to_matrix(rfam_id, use_structure=True, n_max=n_max, complexity=complexity, nbits=nbits)\n",
    "        #NOTE: use the same split given by the sequence similarity\n",
    "        struct_X_train = struct_X[train_ids]\n",
    "        struct_X_test = struct_X[test_ids]\n",
    "        struct_train_list.append(struct_X_train)\n",
    "        struct_test_list.append(struct_X_test)\n",
    "    seq_X_train = vstack(seq_train_list, format=\"csr\")\n",
    "    seq_X_test = vstack(seq_test_list, format=\"csr\")\n",
    "    struct_X_train = vstack(struct_train_list, format=\"csr\")\n",
    "    struct_X_test = vstack(struct_test_list, format=\"csr\")\n",
    "    target_train = np.array(y_train)\n",
    "    target_test = np.array(y_test)\n",
    "    \n",
    "    return seq_X_train,\\\n",
    "        seq_X_test,\\\n",
    "        struct_X_train,\\\n",
    "        struct_X_test,\\\n",
    "        target_train,\\\n",
    "        target_test\n",
    "\n",
    "rfam_ids=['RF00004','RF00005','RF00015','RF00020','RF00026','RF00169',\n",
    "          'RF00380','RF00386','RF01051','RF01055','RF01234','RF01699',\n",
    "          'RF01701','RF01705','RF01731','RF01734','RF01745','RF01750',\n",
    "          'RF01942','RF01998','RF02005','RF02012','RF02034']\n",
    "\n",
    "print 'num families:', len(rfam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment using 5 families\n"
     ]
    }
   ],
   "source": [
    "data_ids=rfam_ids[0:5]\n",
    "print 'Experiment using %d families' % len(data_ids)\n",
    "prefix='f3_c4nb12_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 58s, sys: 11 s, total: 2min 9s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq_X_train,\\\n",
    "seq_X_test,\\\n",
    "struct_X_train,\\\n",
    "struct_X_test,\\\n",
    "y_train,\\\n",
    "y_test = rfam_data(data_ids, n_max=300, complexity=4, nbits=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved f3_c4nb12_seq_X_train.dat (353,2049)\n",
      "Saved f3_c4nb12_seq_X_test.dat (684,2049)\n",
      "Saved f3_c4nb12_struct_X_train.dat (353,2049)\n",
      "Saved f3_c4nb12_struct_X_test.dat (684,2049)\n",
      "Saved f3_c4nb12_y_train.dat (353)\n",
      "Saved f3_c4nb12_y_test.dat (684)\n",
      "CPU times: user 15 ms, sys: 107 ms, total: 122 ms\n",
      "Wall time: 380 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_data(seq_X_train, fname=prefix+'seq_X_train.dat')\n",
    "save_data(seq_X_test, fname=prefix+'seq_X_test.dat')\n",
    "save_data(struct_X_train, fname=prefix+'struct_X_train.dat')\n",
    "save_data(struct_X_test, fname=prefix+'struct_X_test.dat')\n",
    "save_data(y_train, fname=prefix+'y_train.dat')\n",
    "save_data(y_test, fname=prefix+'y_test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded f3_c4nb12_seq_X_train.dat (353,2049)\n",
      "Loaded f3_c4nb12_seq_X_test.dat (684,2049)\n",
      "Loaded f3_c4nb12_struct_X_train.dat (353,2049)\n",
      "Loaded f3_c4nb12_struct_X_test.dat (684,2049)\n",
      "Loaded f3_c4nb12_y_train.dat (353)\n",
      "Loaded f3_c4nb12_y_test.dat (684)\n",
      "CPU times: user 17 ms, sys: 45.5 ms, total: 62.5 ms\n",
      "Wall time: 61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq_X_train=load_data(fname=prefix+'seq_X_train.dat')\n",
    "seq_X_test=load_data(fname=prefix+'seq_X_test.dat')\n",
    "struct_X_train=load_data(fname=prefix+'struct_X_train.dat')\n",
    "struct_X_test=load_data(fname=prefix+'struct_X_test.dat')\n",
    "y_train=load_data(fname=prefix+'y_train.dat')\n",
    "y_test=load_data(fname=prefix+'y_test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 5.08 ms, total: 5.11 ms\n",
      "Wall time: 5.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sparse to dense arrays\n",
    "Xseq_train = seq_X_train\n",
    "Xseq_test = seq_X_test\n",
    "X_train = struct_X_train\n",
    "X_test = struct_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 ms, sys: 10.2 ms, total: 37.1 ms\n",
      "Wall time: 36.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sparse to dense arrays\n",
    "Xseq_train = seq_X_train.toarray()\n",
    "Xseq_test = seq_X_test.toarray()\n",
    "X_train = struct_X_train.toarray()\n",
    "X_test = struct_X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sequence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on data matrix [353 x 2049]\n",
      "Confusion matrix:\n",
      "[[126   0  18   1   0]\n",
      " [  0  22 226   3   0]\n",
      " [  0   0  61   0   0]\n",
      " [  5   0   9  48   0]\n",
      " [  1  18 106  22  18]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.87      0.91       145\n",
      "          1       0.55      0.09      0.15       251\n",
      "          2       0.15      1.00      0.25        61\n",
      "          3       0.65      0.77      0.71        62\n",
      "          4       1.00      0.11      0.20       165\n",
      "\n",
      "avg / total       0.72      0.40      0.38       684\n",
      "\n",
      "CPU times: user 69.1 ms, sys: 5.33 ms, total: 74.5 ms\n",
      "Wall time: 150 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_perform(Xseq_train, y_train, Xseq_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Structure features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on data matrix [353 x 2049]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[110   1  29   4   1]\n",
      " [  5 136  73  32   5]\n",
      " [ 23   5  28   5   0]\n",
      " [ 12   3  15  31   1]\n",
      " [  1  78  19  37  30]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.76      0.74       145\n",
      "          1       0.61      0.54      0.57       251\n",
      "          2       0.17      0.46      0.25        61\n",
      "          3       0.28      0.50      0.36        62\n",
      "          4       0.81      0.18      0.30       165\n",
      "\n",
      "avg / total       0.61      0.49      0.49       684\n",
      "\n",
      "CPU times: user 77.1 ms, sys: 5.14 ms, total: 82.3 ms\n",
      "Wall time: 150 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_perform(X_train, y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Learned map seq $\\mapsto$ structure features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons: #in [2049] -- #hidden [4098] -- #out [2049]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "seqs_scale = StandardScaler(with_mean=True)\n",
    "data_matrix_in = seqs_scale.fit_transform(Xseq_train)\n",
    "struct_scale = StandardScaler(with_mean=True)\n",
    "data_matrix_out = struct_scale.fit_transform(X_train)\n",
    "n_features_in = data_matrix_in.shape[1]\n",
    "n_features_out = data_matrix_out.shape[1]\n",
    "n_features_hidden = max(n_features_in, n_features_out) * 2\n",
    "print 'n_neurons: #in [%d] -- #hidden [%d] -- #out [%d]' % (n_features_in, n_features_hidden, n_features_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Regressor, Layer\n",
    "\n",
    "net = Regressor(layers=[\n",
    "        Layer(\"Rectifier\", units=n_features_hidden),\n",
    "        Layer(\"Rectifier\", units=n_features_hidden),\n",
    "        Layer(\"Rectifier\", units=n_features_hidden),\n",
    "        Layer(\"Softmax\", units=n_features_out)],\n",
    "                learning_rate=0.000001,\n",
    "                n_iter=100,\n",
    "                regularize='L1',\n",
    "                valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "net.fit(data_matrix_in, data_matrix_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Transform seq features to struct features\n",
    "X_train_pred = net.predict(seqs_scale.transform(Xseq_train))\n",
    "X_test_pred = net.predict(seqs_scale.transform(Xseq_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_perform(X_train_pred, y_train, X_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
